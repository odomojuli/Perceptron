{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red27\green29\blue31;\red235\green236\blue237;}
{\*\expandedcolortbl;;\cssrgb\c14118\c15294\c16078;\cssrgb\c93725\c94118\c94510;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl300\partightenfactor0

\f0\fs26 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 import numpy as np\
from scipy.linalg import pinv2\
\
n_hidden = 10  # hyperparameter\
\
# Training set\
X_train = np.array([[0,0], [0,1], [1,0], [1,1]])\
y_train = [0, 1, 1, 0]\
\
# set hidden layer parameters randomly\
w = np.random.randn(X_train.shape[1], n_hidden)\
b = np.random.randn(n_hidden)\
\
# compute hidden layer activation\
H = np.tanh(np.dot(X_train, w) + b)\
\
# fit output layer parameters\
beta = np.dot(pinv2(H), np.atleast_2d(y_train).T)\
\
# prediction and evaluation\
pred_train = (np.dot(H, beta) > .5).ravel()\
print "Training set accuracy:", np.mean(pred_train == y_train)\
}